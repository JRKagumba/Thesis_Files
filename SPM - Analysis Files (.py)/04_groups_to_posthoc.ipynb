{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "import spm1d\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours={\n",
    "    0:{'name':\"red\",\n",
    "       'value':[\"#FF0000\",\"#FF6666\"]},\n",
    "    10:{'name':\"red-purple\",\n",
    "       'value':[\"#953553\",\"#C96786\"]},\n",
    "    7:{'name':\"purple\",\n",
    "       'value':[\"#6A0DAD\",\"#A031EF\"]},\n",
    "    4:{'name':\"blue-purple\",\n",
    "       'value':[\"#8A2BE2\",\"#BC85EE\"]},\n",
    "    1:{'name':\"blue\",\n",
    "       'value':[\"#0000FF\",\"#6666FF\"]},\n",
    "    11:{'name':\"blue-green\",\n",
    "       'value':[\"#088F8F\",\"#0DF0F0\"]},\n",
    "    2:{'name':\"green\",\n",
    "       'value':[\"#009900\",\"#33CC33\"]},\n",
    "    5:{'name':\"yellow-green\",\n",
    "       'value':[\"#9ACD32\",\"#C2E184\"]},\n",
    "    8:{'name':\"yellow\",\n",
    "       'value':[\"#999900\",\"#FFFF66\"]},\n",
    "    12:{'name':\"yellow-orange\",\n",
    "       'value':[\"#FFAE42\",\"#FFDAA8\"]},\n",
    "    9:{'name':\"orange\",\n",
    "       'value':[\"#FFA500\",\"#FFC966\"]},\n",
    "    6:{'name':\"red-orange\",\n",
    "       'value':[\"#FF5349\",\"#FFB3AF\"]},\n",
    "    3:{'name':\"rose\",\n",
    "       'value':[\"#FF006C\",\"#FF66A7\"]},\n",
    "    13:{'name':\"brown\",\n",
    "       'value':[\"#964B00\",\"#C97E33\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_paths(group_list, task, joint, orientation):\n",
    "\n",
    "    group1 =r\"E:\\Data\\Jarrod_Thesis\\Group1\"\n",
    "    group2 =r\"E:\\Data\\Jarrod_Thesis\\Group2\"\n",
    "    group3 =r\"E:\\Data\\Jarrod_Thesis\\Group3\"\n",
    "\n",
    "    file_path_list=[]\n",
    "\n",
    "    for mocap in [group1,group2,group3]:\n",
    "        for (root,dirs,files) in os.walk(mocap, topdown=False):\n",
    "\n",
    "            for file in files:\n",
    "\n",
    "                for group in group_list:\n",
    "                    \n",
    "                    file_path=os.path.join(root,file)\n",
    "                    file_name=file[:-4]\n",
    "                    \n",
    "                    if (group in file_path) and (joint in file_path) and (orientation in file_path) and (task in file_path) and ('csv' in file_path):\n",
    "                        file_path_list.append(file_path)\n",
    "            #             print(f\"Appended {file_path}\")          \n",
    "            # print ('----------------------------------------------------')\n",
    "\n",
    "    return(file_path_list)\n",
    "\n",
    "# path_list=find_file_paths(['Group1','Group2','Group3'], 'T08', 'Shoulder', 'Right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_directory(task,joint,orientation=''):\n",
    "    \"\"\"\n",
    "    creates file directories\n",
    "    \"\"\"\n",
    "    root_path=r\"E:\\Data\\Jarrod_Thesis\"\n",
    "    new_dir=os.path.join(root_path,'All',task,joint,orientation)\n",
    "    return new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepaths_to_dataframes(path_list):\n",
    "    \"\"\"\n",
    "    Takes in a list of file paths and return a list of dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe_dict={}\n",
    "    for path in path_list:\n",
    "        group_number=path.split('\\\\')[3]\n",
    "        task_number=path.split('\\\\')[4]\n",
    "        joint_type=path.split('\\\\')[5]\n",
    "\n",
    "        if joint_type in ['Elbow','Shoulder']:\n",
    "            joint_type=path.split('\\\\')[5]+'-'+path.split('\\\\')[6]\n",
    "        \n",
    "        data=pd.read_csv(path).iloc[:, 1:]\n",
    "        new_column_names={column_name:f\"{group_number}_{task_number}_{joint_type}\" for column_name in data.columns}\n",
    "        data=data.rename(columns=new_column_names)\n",
    "\n",
    "\n",
    "        dataframe_dict['task']=task_number\n",
    "        dataframe_dict['joint']=joint_type\n",
    "        dataframe_dict[group_number]={}\n",
    "        dataframe_dict[group_number]['data']=data\n",
    "        dataframe_dict[group_number]['length']=len(data)\n",
    "\n",
    "        _joint = path.split('\\\\')[5]\n",
    "        if _joint in ['Elbow','Shoulder']:\n",
    "            directory=find_file_directory(task=path.split('\\\\')[4],\n",
    "                                            joint=path.split('\\\\')[5],\n",
    "                                            orientation=path.split('\\\\')[6])\n",
    "        else:\n",
    "            directory=find_file_directory(task=path.split('\\\\')[4],\n",
    "                                            joint=path.split('\\\\')[5],\n",
    "                                            orientation='')\n",
    "\n",
    "    return directory, dataframe_dict\n",
    "\n",
    "\n",
    "\n",
    "# directory, dataframe_dict=filepaths_to_dataframes(path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_dataframes(df_tuple,df_dict):\n",
    "    \"\"\"\n",
    "    -takes in a tuple of group names and the dataframe_dict\n",
    "    -returns 2 interpolated dataframes\n",
    "    \"\"\"\n",
    "    name_1=df_tuple[0]\n",
    "    name_2=df_tuple[1]\n",
    "\n",
    "    length_1=df_dict[name_1]['length']\n",
    "    length_2=df_dict[name_2]['length']\n",
    "\n",
    "    MaxIndex=max(length_1,length_2)\n",
    "\n",
    "\n",
    "    interp_data_dict={}\n",
    "    for name in [name_1,name_2]:\n",
    "        if df_dict[name]['length']==MaxIndex:\n",
    "            interp_data_dict[name]=df_dict[name]['data']\n",
    "        \n",
    "        else:\n",
    "            count=1000\n",
    "            data_dict={}\n",
    "            shorter_data=df_dict[name]['data']\n",
    "            for (columnName, columnData) in shorter_data.iteritems():\n",
    "\n",
    "                t2 = columnData.dropna()\n",
    "                x0 = range(t2.size)\n",
    "                x1 = np.linspace(0, t2.size, num=MaxIndex)\n",
    "\n",
    "                data_dict[f\"{columnName}_{count}\"]= pd.Series(np.interp(x1, x0, t2, left=None, right=None))\n",
    "                count+=1\n",
    "\n",
    "                interp_data=pd.DataFrame(data_dict)\n",
    "                new_column_names={column_name:column_name[:-5] for column_name in interp_data.columns}\n",
    "                interp_data=interp_data.rename(columns=new_column_names)\n",
    "            \n",
    "            interp_data_dict[name]=interp_data\n",
    "\n",
    "    return (MaxIndex, interp_data_dict)\n",
    "\n",
    "\n",
    "# MaxIndex, interp_data_dict=interpolate_dataframes(group_combo_lst[0],dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spm_TTEST_stats(interpolated_data_1, interpolated_data_2):\n",
    "\n",
    "    YA=interpolated_data_1\n",
    "    YA=YA.T.to_numpy()\n",
    "\n",
    "    YB=interpolated_data_2\n",
    "    YB=YB.T.to_numpy()\n",
    "\n",
    "    alpha      = 0.05\n",
    "    t          = spm1d.stats.ttest2(YA, YB, equal_var=True)\n",
    "    ti         = t.inference(alpha, two_tailed=True, interp=True)\n",
    "\n",
    "    return(alpha, t, ti)\n",
    "\n",
    "# alpha, t, ti = compute_spm_TTEST_stats(interp_data_dict['Group1'], interp_data_dict['Group2'])\n",
    "\n",
    "# ti.plot()\n",
    "# ti.plot_threshold_label(fontsize=8)\n",
    "# ti.plot_p_values(size=10, offset_all_clusters=(0,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def plot_and_save_TTEST(directory, dataframe_dict):\n",
    "\n",
    "    group_lst=['Group1','Group2','Group3']\n",
    "    group_combo_lst=[]\n",
    "    combos = combinations(group_lst, 2)\n",
    "    for combo in combos:\n",
    "        group_combo_lst.append(combo)\n",
    "\n",
    "  \n",
    "    task=dataframe_dict['task']\n",
    "    joint=dataframe_dict['joint']\n",
    "\n",
    "\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, sharex=False,figsize=(18, 27))\n",
    "    \n",
    "    ###################################################-compute and plot TTESTS-###################################################\n",
    "    \n",
    "    for index, ax in enumerate([ax0, ax1, ax2]):\n",
    "    \n",
    "        group_i=group_combo_lst[index][0]\n",
    "        group_j=group_combo_lst[index][1]\n",
    "        \n",
    "        plot_name=f\"{group_i}-{group_j}_{task}_{joint}\"\n",
    "        MaxIndex, interp_data_dict=interpolate_dataframes(group_combo_lst[index],dataframe_dict)\n",
    "        alpha, t, ti = compute_spm_TTEST_stats(interp_data_dict[group_i], interp_data_dict[group_j])\n",
    "\n",
    "        ti.plot(ax=ax,color='k',label='Between Groups-Post Hoc')\n",
    "        ti.plot_threshold_label(ax=ax, fontsize=8)\n",
    "        ti.plot_p_values(size=10, offset_all_clusters=(0,0.9), ax=ax)\n",
    "\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.set_title(f\"{plot_name}_TTEST\",size=15)    \n",
    "        ax.set_ylabel('SPM {t}', fontsize=15)\n",
    "        ax.set_xlabel('Time (%)', size=15)\n",
    "\n",
    "        x0, x1, y0, y1 = ax.axis()\n",
    "        margin_x = 0.01 * (x1-x0)\n",
    "        margin_y = 0.01 * (y1-y0)\n",
    "        ax.axis((x0 - margin_x,\n",
    "                    x1 + margin_x,\n",
    "                    y0 - margin_y,\n",
    "                    y1 + margin_y))\n",
    "\n",
    "        ax.margins(x=0.01)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(MaxIndex/5))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(MaxIndex/20))\n",
    "        ax.xaxis.set_major_formatter(ticker.PercentFormatter(xmax=MaxIndex))\n",
    "    \n",
    "\n",
    "\n",
    "    fig.suptitle(f'{task}_{joint}',size=22,y=0.92)\n",
    "    # plt.show()\n",
    "    image_file_path=os.path.join(directory,f\"{task}_{joint}_TTEST_image.png\")\n",
    "    plt.savefig(image_file_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# plot_and_save_TTEST(directory, dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joints(joint,orientation=''):\n",
    "    joints_list=['Neck','Trunk','COM_X','COM_Y','COM_Z','Elbow','Shoulder']\n",
    "\n",
    "    if joint not in joints_list:\n",
    "        return('Invalid joint name')\n",
    "    elif (joint == 'Elbow') and (orientation not in ['Left','Right']):\n",
    "        return(f'Invalid {joint} orientation')\n",
    "    elif (joint == 'Shoulder') and (orientation not in ['Left','Right']):\n",
    "        return(f'Invalid {joint} orientation')\n",
    "\n",
    "    if joint in [joint for joint in joints_list if joint not in ['Elbow','Shoulder']]:\n",
    "        orientation=''\n",
    "    \n",
    "    return (joint, orientation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TTEST_plots_with_data(_joint,_task,_orientation):\n",
    "    joint, orientation =joints(_joint, _orientation)\n",
    "    task=_task\n",
    "\n",
    "    print(f'{_task}__{_joint}-{_orientation}')\n",
    "\n",
    "    path_list=                  find_file_paths(['Group1','Group2','Group3'], task, joint, orientation)\n",
    "    print(\"\\tStep 1:\\tFile paths found\")\n",
    "\n",
    "    directory, dataframe_dict=  filepaths_to_dataframes(path_list)\n",
    "    print(\"\\tStep 2:\\tDestination directory and dataframe dict created\")\n",
    "\n",
    "    plot_and_save_TTEST(directory, dataframe_dict)\n",
    "    print(\"\\tStep 3:\\tPlots created and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T05__COM_Z-\n",
      "\tStep 1:\tFile paths found\n",
      "\tStep 2:\tDestination directory and dataframe dict created\n",
      "\tStep 3:\tPlots created and saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "['Neck','Trunk','COM_X','COM_Y','COM_Z','Elbow','Shoulder']\n",
    "['T01','T02','T03','T04','T05','T06','T07','T08','T09','T10','T11','T12','T13','T14']\n",
    "\n",
    "\n",
    "\n",
    "for _task in ['T05']:\n",
    "    for _joint in ['COM_Z']:\n",
    "        if _joint in ['Elbow']:\n",
    "            for _orientation in ['Right']:\n",
    "                create_TTEST_plots_with_data(_joint,_task,_orientation)\n",
    "        else:\n",
    "            create_TTEST_plots_with_data(_joint,_task,_orientation='')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c543a0a8d78370d5d5f7f6eca405d0a8e4ac3df93d3f544c29eb0cbbdc6e4903"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Biomechanical_Analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
